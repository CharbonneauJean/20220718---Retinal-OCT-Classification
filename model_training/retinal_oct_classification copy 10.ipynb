{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IdFojbjNj6VJ"
      },
      "source": [
        "# Detecting Retina Damage From Optical Coherence Tomography (OCT) Images, using Transfer Learning on VGG16 CNN Model\n",
        "## Context\n",
        "Retinal Optical Coherence Tomography (OCT) is an imaging technique used to capture high-resolution cross sections of the retinas of living patients. Approximately 30 million OCT scans are performed each year, and the analysis and interpretation of these images takes up a significant amount of time (Swanson and Fujimoto, 2017).\n",
        "\n",
        "![Figure 1.](https://i.imgur.com/fSTeZMd.png)\n",
        "\n",
        "Figure 1. Representative Optical Coherence Tomography Images and the Workflow Diagram \\[Kermany et. al. 2018\\]\n",
        "\n",
        "(A) (Far left) Choroidal Neo-Vascularization (CNV) with neovascular membrane (white arrowheads) and associated subretinal fluid (arrows). (Middle left) Diabetic Macular Edema (DME) with retinal-thickening-associated intraretinal fluid (arrows). (Middle right) Multiple drusen (arrowheads) present in early AMD. (Far right) Normal retina with preserved foveal contour and absence of any retinal fluid/edema.\n",
        "\n",
        "## Content\n",
        "* The dataset is organized into 3 folders (train, test, val) and contains subfolders for each image category (NORMAL,CNV,DME,DRUSEN). There are 84,495 X-Ray images (JPEG) and 4 categories (NORMAL,CNV,DME,DRUSEN).\n",
        "* Images are labeled as (disease)-(randomized patient ID)-(image number by this patient) and split into 4 directories: CNV, DME, DRUSEN, and NORMAL.\n",
        "\n",
        "* Optical coherence tomography (OCT) images (Spectralis OCT, Heidelberg Engineering, Germany) were selected from retrospective cohorts of adult patients from the Shiley Eye Institute of the University of California San Diego, the California Retinal Research Foundation, Medical Center Ophthalmology Associates, the Shanghai First Peopleâ€™s Hospital, and Beijing Tongren Eye Center between July 1, 2013 and March 1, 2017.\n",
        "\n",
        "## Acknowledgements\n",
        "* Data: https://data.mendeley.com/datasets/rscbjbr9sj/2\n",
        "* Citation: http://www.cell.com/cell/fulltext/S0092-8674(18)30154-5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xBeaBcUzj6VO"
      },
      "source": [
        "## Installing and Importing Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "id": "kwPBg7gNj6VR",
        "scrolled": false
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-07-22 10:50:36.884996: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
            "2022-07-22 10:50:36.885011: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from glob import glob\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from numpy import expand_dims\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import seaborn as sn\n",
        "from skimage.transform import resize\n",
        "from skimage.color import gray2rgb\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from IPython.display import SVG\n",
        "import keract\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import applications, optimizers\n",
        "from tensorflow.keras.models import Model, Sequential, load_model\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
        "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
        "from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input\n",
        "from tensorflow.keras.utils import to_categorical, model_to_dot, plot_model\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, CSVLogger, ReduceLROnPlateau"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2tdndSE9j6VS"
      },
      "source": [
        "## Importing Dataset and Data Pre-Processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "1E-3ZqlIj6VT",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "data_dir = \"/home/jean/Desktop/WorkspaceBigFiles/RetinalE2/\"\n",
        "train_data_dir= '/home/jean/Desktop/WorkspaceBigFiles/RetinalE2/train/'\n",
        "val_data_dir= '/home/jean/Desktop/WorkspaceBigFiles/RetinalE2/val/'\n",
        "test_data_dir= '/home/jean/Desktop/WorkspaceBigFiles/RetinalE2/test/'\n",
        "img_width, img_height = 144, 144 \n",
        "channels = 3\n",
        "batch_size = 32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 497
        },
        "id": "DWH6wRcwj6VU",
        "outputId": "5eade3f8-f536-4333-e5d9-7313640c88c1",
        "scrolled": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "37205\n"
          ]
        }
      ],
      "source": [
        "cnv_images = len(glob(train_data_dir + 'CNV/*.jpeg'))\n",
        "print(cnv_images)\n",
        "dme_images = len(glob(train_data_dir + 'DME/*.jpeg'))\n",
        "drusen_images = len(glob(train_data_dir + 'DRUSEN/*.jpeg'))\n",
        "normal_images = len(glob(train_data_dir + 'NORMAL/*.jpeg'))\n",
        "data= {'CNV': cnv_images, 'DME': dme_images, 'DRUSEN': drusen_images, 'NORMAL': normal_images}\n",
        "labels = list(data.keys()) \n",
        "count = list(data.values())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GH5jQNJPj6VV"
      },
      "source": [
        "### Image Histogram (Tonal Distribution)\n",
        "* Histogram of a normal retina image in the train dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        },
        "id": "4m7GVZBcj6VV",
        "outputId": "9bed0a9b-46ca-40a0-df32-bb845d0fa0ae",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "image = mpimg.imread(data_dir + '/train/NORMAL/NORMAL-1001666-1.jpeg')\n",
        "color_img= gray2rgb(resize(image, (128, 128)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HHLofnAxj6VX"
      },
      "source": [
        "### Keras Data Generators"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "crop_length = 40\n",
        "\n",
        "def crop(image):\n",
        "    return image[crop_length:image.shape[0]-crop_length, crop_length:image.shape[1]-crop_length]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "H0EPw85rj6VY",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "train_datagen = ImageDataGenerator(\n",
        "    rescale= 1./255,\n",
        "    horizontal_flip= True,\n",
        "    rotation_range= 10,\n",
        "    zoom_range= (0.7, 0.9),\n",
        "    width_shift_range= 0.10,\n",
        "    fill_mode= 'constant',\n",
        "    height_shift_range= 0.10,   \n",
        "    brightness_range= (0.55, 0.9),\n",
        "    preprocessing_function= crop,\n",
        "    )\n",
        "\n",
        "\n",
        "valid_test_datagen = ImageDataGenerator(\n",
        "    rescale= 1./255, \n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "73kQ9HVkj6VY",
        "outputId": "80cf2772-20af-4d3f-885b-8088bf78e957",
        "scrolled": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 83484 images belonging to 4 classes.\n",
            "Found 32 images belonging to 4 classes.\n",
            "Found 968 images belonging to 4 classes.\n"
          ]
        }
      ],
      "source": [
        "train_generator = train_datagen.flow_from_directory(  \n",
        "    train_data_dir,  \n",
        "    target_size= (img_width, img_height),\n",
        "    color_mode= 'rgb',\n",
        "    batch_size= batch_size,  \n",
        "    class_mode= 'categorical',\n",
        "    shuffle= True, \n",
        "    seed= 1337\n",
        ") \n",
        "\n",
        "valid_generator = valid_test_datagen.flow_from_directory(\n",
        "    val_data_dir,\n",
        "    target_size= (img_width, img_height),\n",
        "    color_mode= 'rgb',\n",
        "    batch_size= batch_size,  \n",
        "    class_mode= 'categorical',\n",
        "    shuffle= True, \n",
        "    seed= 1337\n",
        ")\n",
        "\n",
        "test_generator = valid_test_datagen.flow_from_directory(  \n",
        "    test_data_dir,  \n",
        "    target_size= (img_width, img_height), \n",
        "    color_mode= 'rgb',\n",
        "    batch_size= batch_size,        \n",
        "    class_mode= 'categorical',\n",
        "    shuffle= False, \n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "YsZD84kXj6VY",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "num_classes = len(train_generator.class_indices)  \n",
        "train_labels = train_generator.classes \n",
        "train_labels = to_categorical(train_labels, num_classes=num_classes)\n",
        "valid_labels = valid_generator.classes \n",
        "valid_labels = to_categorical(valid_labels, num_classes=num_classes)\n",
        "nb_train_samples = len(train_generator.filenames)  \n",
        "nb_valid_samples = len(valid_generator.filenames)\n",
        "nb_test_samples = len(test_generator.filenames)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UUOcv2u8j6VY"
      },
      "source": [
        "# Model\n",
        "* VGG16 CNN architecture is used for calssification.\n",
        "* Pretrained on the 'ImageNet' dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SKzrizgVj6VY",
        "outputId": "141dc843-3366-40ee-a70a-48286d4aadbe",
        "scrolled": false
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-07-22 10:50:39.483189: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-07-22 10:50:39.483382: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
            "2022-07-22 10:50:39.483428: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
            "2022-07-22 10:50:39.483465: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
            "2022-07-22 10:50:39.483506: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
            "2022-07-22 10:50:39.483543: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
            "2022-07-22 10:50:39.483579: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
            "2022-07-22 10:50:39.483613: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
            "2022-07-22 10:50:39.483647: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
            "2022-07-22 10:50:39.483653: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
            "Skipping registering GPU devices...\n",
            "2022-07-22 10:50:39.483982: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 144, 144, 3)]     0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 144, 144, 64)      1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 144, 144, 64)      36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 72, 72, 64)        0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 72, 72, 128)       73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 72, 72, 128)       147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 36, 36, 128)       0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 36, 36, 256)       295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 36, 36, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 36, 36, 256)       590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 18, 18, 256)       0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 18, 18, 512)       1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 18, 18, 512)       2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 18, 18, 512)       2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 9, 9, 512)         0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 9, 9, 512)         2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 9, 9, 512)         2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 9, 9, 512)         2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 4, 4, 512)         0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14,714,688\n",
            "Trainable params: 14,714,688\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "vgg16 = VGG16(include_top= False, input_shape= (img_width, img_height, channels), weights= 'imagenet')\n",
        "vgg16.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lblkInHHj6VZ",
        "outputId": "e99f2f45-f6a4-4d62-fa52-d37123117a02",
        "scrolled": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " block1_conv1 (Conv2D)       (None, 144, 144, 64)      1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 144, 144, 64)      36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 72, 72, 64)        0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 72, 72, 128)       73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 72, 72, 128)       147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 36, 36, 128)       0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 36, 36, 256)       295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 36, 36, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 36, 36, 256)       590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 18, 18, 256)       0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 18, 18, 512)       1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 18, 18, 512)       2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 18, 18, 512)       2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 9, 9, 512)         0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 9, 9, 512)         2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 9, 9, 512)         2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 9, 9, 512)         2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 4, 4, 512)         0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 8192)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               1048704   \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 32)                0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 4)                 132       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 15,773,860\n",
            "Trainable params: 1,059,172\n",
            "Non-trainable params: 14,714,688\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model = Sequential()\n",
        "\n",
        "for layer in vgg16.layers:\n",
        "    model.add(layer)\n",
        "\n",
        "for layer in model.layers:\n",
        "    layer.trainable= False\n",
        "\n",
        "model.add(Flatten(input_shape= (4, 4, 512)))\n",
        "model.add(Dense(128, activation= 'relu'))\n",
        "model.add(Dense(64, activation= 'relu'))\n",
        "model.add(Dense(32, activation= 'relu'))\n",
        "model.add(Dropout(0.15))\n",
        "model.add(Dense(4,activation='softmax'))\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iiHvHOrdj6VZ"
      },
      "source": [
        "## Baseline Model Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oA7oUUXEj6VZ",
        "outputId": "3f2e3269-c0b7-4c00-c56d-f109f8e42fc0",
        "scrolled": false
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/jean/miniconda3/envs/retinal/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "#model.compile(optimizer= keras.optimizers.Adam(lr= 0.0001), loss= 'categorical_crossentropy', metrics= ['accuracy'])\n",
        "model.compile(optimizer=keras.optimizers.SGD(lr=0.001, momentum=0.9), loss= 'categorical_crossentropy', metrics= ['accuracy'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Num GPUs Available:  0\n"
          ]
        }
      ],
      "source": [
        "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hasHQMV2j6VZ",
        "outputId": "17791ec2-936e-4e34-9a6b-9512f4d4899f"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "could not broadcast input array from shape (64,64,3) into shape (144,144,3)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[1;32m/home/jean/Desktop/Workspace/20220718---Retinal-OCT-Classification/model_training/retinal_oct_classification copy 10.ipynb Cell 20\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/jean/Desktop/Workspace/20220718---Retinal-OCT-Classification/model_training/retinal_oct_classification%20copy%2010.ipynb#ch0000019?line=9'>10</a>\u001b[0m earlystop \u001b[39m=\u001b[39m EarlyStopping(monitor\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mval_accuracy\u001b[39m\u001b[39m'\u001b[39m, patience\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m, verbose\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/jean/Desktop/Workspace/20220718---Retinal-OCT-Classification/model_training/retinal_oct_classification%20copy%2010.ipynb#ch0000019?line=10'>11</a>\u001b[0m callbacks_list \u001b[39m=\u001b[39m [earlystop,checkpoint]\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/jean/Desktop/Workspace/20220718---Retinal-OCT-Classification/model_training/retinal_oct_classification%20copy%2010.ipynb#ch0000019?line=11'>12</a>\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(train_generator, \n\u001b[1;32m     <a href='vscode-notebook-cell:/home/jean/Desktop/Workspace/20220718---Retinal-OCT-Classification/model_training/retinal_oct_classification%20copy%2010.ipynb#ch0000019?line=12'>13</a>\u001b[0m                         epochs\u001b[39m=\u001b[39;49mnumepochs, \n\u001b[1;32m     <a href='vscode-notebook-cell:/home/jean/Desktop/Workspace/20220718---Retinal-OCT-Classification/model_training/retinal_oct_classification%20copy%2010.ipynb#ch0000019?line=13'>14</a>\u001b[0m                         batch_size \u001b[39m=\u001b[39;49m batch_size,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/jean/Desktop/Workspace/20220718---Retinal-OCT-Classification/model_training/retinal_oct_classification%20copy%2010.ipynb#ch0000019?line=14'>15</a>\u001b[0m                         validation_data\u001b[39m=\u001b[39;49mvalid_generator, \n\u001b[1;32m     <a href='vscode-notebook-cell:/home/jean/Desktop/Workspace/20220718---Retinal-OCT-Classification/model_training/retinal_oct_classification%20copy%2010.ipynb#ch0000019?line=15'>16</a>\u001b[0m                         verbose\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/jean/Desktop/Workspace/20220718---Retinal-OCT-Classification/model_training/retinal_oct_classification%20copy%2010.ipynb#ch0000019?line=16'>17</a>\u001b[0m                         callbacks \u001b[39m=\u001b[39;49m callbacks_list)\n",
            "File \u001b[0;32m~/miniconda3/envs/retinal/lib/python3.9/site-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m---> 67\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     68\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
            "File \u001b[0;32m~/miniconda3/envs/retinal/lib/python3.9/site-packages/keras/preprocessing/image.py:352\u001b[0m, in \u001b[0;36mBatchFromFilesMixin._get_batches_of_transformed_samples\u001b[0;34m(self, index_array)\u001b[0m\n\u001b[1;32m    350\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mimage_data_generator\u001b[39m.\u001b[39mapply_transform(x, params)\n\u001b[1;32m    351\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mimage_data_generator\u001b[39m.\u001b[39mstandardize(x)\n\u001b[0;32m--> 352\u001b[0m   batch_x[i] \u001b[39m=\u001b[39m x\n\u001b[1;32m    353\u001b[0m \u001b[39m# optionally save augmented images to disk for debugging purposes\u001b[39;00m\n\u001b[1;32m    354\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msave_to_dir:\n",
            "\u001b[0;31mValueError\u001b[0m: could not broadcast input array from shape (64,64,3) into shape (144,144,3)"
          ]
        }
      ],
      "source": [
        "numepochs = 10\n",
        "batch_size = 32\n",
        "checkpoint_filepath = '/tmp/checkpoint'\n",
        "checkpoint = ModelCheckpoint(\n",
        "    filepath=checkpoint_filepath,\n",
        "    save_weights_only=True,\n",
        "    monitor='val_accuracy',\n",
        "    mode='max',\n",
        "    save_best_only=True)\n",
        "earlystop = EarlyStopping(monitor='val_accuracy', patience=5, verbose=1)\n",
        "callbacks_list = [earlystop,checkpoint]\n",
        "history = model.fit(train_generator, \n",
        "                        epochs=numepochs, \n",
        "                        batch_size = batch_size,\n",
        "                        validation_data=valid_generator, \n",
        "                        verbose=1,\n",
        "                        callbacks = callbacks_list)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8jHdPPPtxJc1"
      },
      "source": [
        "Evaluations on Test Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c4EBzCSWj6Va",
        "outputId": "d5baf246-747d-4dc4-ea9c-a5315812e85f",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "(eval_loss, eval_accuracy) = model.evaluate(test_generator, batch_size= batch_size, verbose= 1)\n",
        "print('Test Loss: ', eval_loss)\n",
        "print('Test Accuracy: ', eval_accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 613
        },
        "id": "PLrNe_BLw209",
        "outputId": "b4f45ee7-8554-4eeb-afe1-9db456c2ddbc"
      },
      "outputs": [],
      "source": [
        "plt.subplot()\n",
        "plt.rcParams['figure.figsize'] = (6.0, 4.0)\n",
        "plt.title('Baseline Model Accuracy')\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.legend(['Training Accuracy','Validation Accuracy'])\n",
        "plt.savefig('baseline_acc_epoch.png', transparent= False, bbox_inches= 'tight', dpi= 400)\n",
        "plt.show()\n",
        "\n",
        "plt.subplot()\n",
        "plt.title('Baseline Model Loss')\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.legend(['Training Loss','Validation Loss'])\n",
        "plt.savefig('baseline_loss_epoch.png', transparent= False, bbox_inches= 'tight', dpi= 400)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 750
        },
        "id": "XEyYvvPCxFwa",
        "outputId": "9fa8bc42-2d1c-409b-c9c8-4eeddbb1d23a"
      },
      "outputs": [],
      "source": [
        "Y_pred = model.predict(test_generator, nb_test_samples // batch_size+1)\n",
        "y_pred = np.argmax(Y_pred, axis=1)\n",
        "cm = confusion_matrix(test_generator.classes, y_pred)\n",
        "df_cm = pd.DataFrame(cm, list(test_generator.class_indices.keys()), list(test_generator.class_indices.keys()))\n",
        "fig, ax = plt.subplots(figsize=(10,8))\n",
        "sn.set(font_scale=1.4) # for label size\n",
        "sn.heatmap(df_cm, annot=True, annot_kws={\"size\": 16}, cmap=plt.cm.Blues)\n",
        "plt.title('Confusion Matrix\\n')\n",
        "plt.savefig('confusion_matrix.png', transparent= False, bbox_inches= 'tight', dpi= 400)\n",
        "plt.show()\n",
        "\n",
        "print('Classification Report\\n')\n",
        "target_names = list(test_generator.class_indices.keys())\n",
        "print(classification_report(test_generator.classes, y_pred, target_names=target_names))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e6UmPPNNj6Va"
      },
      "source": [
        "Save the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PmcQoAD8j6Va",
        "outputId": "3d6896f6-c675-469b-c6b5-7cc1533d2974"
      },
      "outputs": [],
      "source": [
        "# save model and architecture to single file\n",
        "model.save(\"retinal-oct_finalJean.h5\")\n",
        "print(\"Saved model to disk\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oaz-a9a_GCB8"
      },
      "source": [
        "Prediction test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EYKm6c3MAIX7",
        "outputId": "4f05792f-50fc-4fc3-b9f6-e464afaa67ef"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "import io\n",
        "model = load_model('retinal-oct_finalJean_2.h5')\n",
        "model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
        "from keras import utils\n",
        "\n",
        "test_image = utils.load_img(\"/home/jean/Desktop/WorkspaceBigFiles/RetinalE2/test/CNV/CNV-1016042-1.jpeg\", target_size = (150, 150)) \n",
        "test_image = utils.img_to_array(test_image)\n",
        "test_image = np.expand_dims(test_image, axis = 0)\n",
        "\n",
        "#predict the result\n",
        "result = np.argmax(model.predict(test_image))\n",
        "print(result)\n",
        "print(list(train_generator.class_indices.keys())[list(train_generator.class_indices.values()).index(result)])"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "retinal-oct-classification.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.10.4 ('retinal')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "vscode": {
      "interpreter": {
        "hash": "06376f8bbd849a0fcbd3cfea9ef40a5390e4caecc8a1454ea21633b1b9dc0a61"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
